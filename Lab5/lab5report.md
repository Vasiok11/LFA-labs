# Chomsky Normal Form: Implementation and Analysis
### Course: Formal Languages & Finite Automata
### Author: Pascari Vasile, Variant 23

----

## Theory

### Context-Free Grammars

A **context-free grammar (CFG)** is a formal grammar used to describe the syntax of programming languages, natural languages, and other formal languages. A CFG is defined by a 4-tuple G = (Vn, Vt, P, S) where:
- Vn is a finite set of non-terminal symbols
- Vt is a finite set of terminal symbols
- P is a finite set of production rules of the form A → α, where A ∈ Vn and α ∈ (Vn ∪ Vt)*
- S ∈ Vn is the start symbol

Context-free grammars are essential in compiler design, language processing, and formal language theory. They provide a way to describe the syntax of languages with recursive structures like nested expressions or balanced parentheses.

### Chomsky Normal Form

**Chomsky Normal Form (CNF)** is a simplified form of context-free grammar where all production rules satisfy one of the following conditions:
1. A → BC (where B and C are non-terminals)
2. A → a (where a is a terminal)
3. S → ε (only allowed if the empty string is in the language)

Converting a CFG to CNF is vital for several reasons:
- It simplifies parsing algorithms (like the CYK algorithm)
- It maintains the same generative power as the original grammar
- It standardizes grammar representation for theoretical analysis
- It eliminates problematic productions like unit rules and ε-productions

The conversion to CNF, while preserving the language generated by the original grammar, requires several transformation steps that incrementally restructure the grammar rules.

## Objectives

The primary objectives of this implementation are to:

1. **Create a Comprehensive Grammar Normalizer**:
   - Develop a class that can transform any context-free grammar into Chomsky Normal Form
   - Ensure the transformation preserves the language generated by the original grammar

2. **Implement Standard Transformation Steps**:
   - Eliminate ε-productions (empty productions)
   - Eliminate unit productions (A → B where B is a non-terminal)
   - Remove inaccessible symbols
   - Remove non-productive symbols
   - Convert remaining rules to CNF format

3. **Demonstrate Correctness Through Example Grammars**:
   - Test the implementation with various grammar variants
   - Validate that each transformation step produces the expected output
   - Ensure the final grammar adheres to CNF constraints

## Implementation Description

The implementation consists of a `ChomskyNormalizer` class that systematically transforms a context-free grammar into Chomsky Normal Form through a series of well-defined steps.

### ChomskyNormalizer Class

At the foundation of our implementation lies the `ChomskyNormalizer` class, which encapsulates all the necessary functionality to transform a context-free grammar into Chomsky Normal Form. The constructor initiates the transformation process by setting up essential data structures:

```python
def __init__(self, Vn, Vt, P, S):
    self.Vn = Vn.copy()  
    self.Vt = Vt.copy()
    self.P = self._parse_productions(P)
    self.S = S
    self.terminal_map = {}  
    self.pair_map = OrderedDict()  
    self.new_nonterm_counter = 0
    self.original_S = S  
```

The constructor carefully creates copies of input collections to preserve the original grammar throughout the transformation. It also prepares dictionaries that will track newly created non-terminals during the conversion process - `terminal_map` for replacing terminal symbols and `pair_map` for managing the splitting of long rules.

### _parse_productions method

Converting the input grammar into a workable format presents the first challenge. The `_parse_productions` function tackles this by transforming a string-based representation into a structured dictionary:

```python
def _parse_productions(self, P):
    productions = {}
    for rule in P.split(','):
        rule = rule.strip()
        if not rule:
            continue
        left, right = rule.split('->')
        left = left.strip()
        alternatives = [alt.strip() for alt in right.split('|')]
        productions[left] = alternatives
    return productions
```

Rather than just storing raw text, this function dissects each production rule, splitting it at the arrow symbol and organizing alternatives separated by vertical bars. The resulting dictionary maps each non-terminal to its various production alternatives, creating a more programmatically accessible structure.

### _get_new_nonterminal method

Throughout the conversion process, the algorithm needs to introduce new non-terminal symbols. A simple yet elegant solution comes in the form of the `_get_new_nonterminal` function:

```python
def _get_new_nonterminal(self, prefix='N'):
    new_nonterm = f"{prefix}{self.new_nonterm_counter}"
    self.new_nonterm_counter += 1
    return new_nonterm
```

Featuring a monotonically increasing counter, this function creates guaranteed-unique symbol names. The prefix parameter adds semantic meaning to the generated symbols - 'N' for general non-terminals, 'T' for terminal replacements, and 'S' for start symbol variants. This naming convention improves readability of the transformed grammar and eases debugging.

### eliminate_epsilons method

The removal of ε-productions represents the first major transformation step. The `eliminate_epsilons` function employs a sophisticated algorithm to identify and replace all empty productions while preserving the grammar's generative power:

```python
def eliminate_epsilons(self):
    nullable = set()
    changed = True
    while changed:
        changed = False
        for left, rights in self.P.items():
            if left in nullable:
                continue  

            for rule in rights:
                if rule == 'ε' or (rule and all(sym in nullable for sym in rule.split())):
                    nullable.add(left)
                    changed = True
                    break

    has_empty_string = self.S in nullable

    new_P = {}
    for left, rights in self.P.items():
        new_rules = set()
        for rule in rights:
            if rule == 'ε':
                continue

            symbols = rule.split()
            nullable_indices = [i for i, sym in enumerate(symbols) if sym in nullable]

            for r in range(len(nullable_indices) + 1):
                for indices_to_remove in itertools.combinations(nullable_indices, r):
                    new_rule = [sym for i, sym in enumerate(symbols) if i not in indices_to_remove]
                    if new_rule:  
                        new_rules.add(' '.join(new_rule))

        if new_rules:  
            new_P[left] = list(new_rules)

    if has_empty_string:
        new_S = self._get_new_nonterminal('S')
        self.Vn.append(new_S)
        new_P[new_S] = [self.S]
        if 'ε' not in new_P.get(self.S, []):
            new_P.setdefault(self.S, []).append('ε')
        self.original_S = self.S  
        self.S = new_S  
    self.P = new_P
```

The algorithm works in three distinct phases. First, it computes the set of "nullable" symbols - those that can directly or indirectly derive the empty string - using a fixed-point iteration. Then, leveraging the power of combinatorics, it generates alternative versions of each rule by systematically removing nullable symbols. This creates all possible production variants that would result from the optional presence of these symbols. Finally, the code handles the special case where the grammar accepts the empty string by creating a new start symbol, ensuring this capability is preserved after transformation.

### eliminate_unit_rules method

Unit productions (A → B where B is a non-terminal) present a particular challenge in CNF conversion. The `eliminate_unit_rules` function tackles this problem through graph theory principles:

```python
def eliminate_unit_rules(self):
    unit_pairs = {}  

    for left, rights in self.P.items():
        unit_pairs[left] = {left}  
        for rule in rights:
            if rule in self.Vn:  
                unit_pairs[left].add(rule)

    changed = True
    while changed:
        changed = False
        for A in self.Vn:
            current_set = unit_pairs.get(A, set())
            new_set = current_set.copy()

            for B in current_set:
                new_set.update(unit_pairs.get(B, set()))

            if len(new_set) > len(current_set):
                unit_pairs[A] = new_set
                changed = True

    new_P = {}
    for A in self.Vn:
        new_rules = []
        for B in unit_pairs.get(A, set()):
            for rule in self.P.get(B, []):
                if rule not in self.Vn and rule != 'ε':  
                    new_rules.append(rule)

        if new_rules:  
            new_P[A] = new_rules

    self.P = new_P
```

This function approaches the problem by viewing unit productions as edges in a directed graph, where non-terminals form the vertices. It first builds a directed graph representation through the `unit_pairs` dictionary, capturing immediate unit relationships. Then, applying a classic transitive closure algorithm, it discovers all indirect derivation paths between non-terminals. With this complete map of unit relationships, the final phase performs a sophisticated substitution – replacing each unit rule with the concrete, non-unit rules of its target non-terminal. This effectively "flattens" multi-step derivations into direct ones, eliminating the intermediate unit steps.

### eliminate_inaccessible_symbols method

Grammar optimization continues with the removal of inaccessible symbols - those that cannot be reached from the start symbol in any derivation. The `eliminate_inaccessible_symbols` function employs a classic graph traversal approach:

```python
def eliminate_inaccessible_symbols(self):
    accessible = set()
    queue = [self.S]

    while queue:
        current = queue.pop(0)
        if current not in accessible:
            accessible.add(current)
            for rule in self.P.get(current, []):
                for sym in rule.split():
                    if sym in self.Vn and sym not in accessible:
                        queue.append(sym)

    self.Vn = [nt for nt in self.Vn if nt in accessible]

    self.P = {k: v for k, v in self.P.items() if k in accessible}
```

Leveraging breadth-first search, this algorithm explores the grammar's structure starting from the initial symbol S. The queue-based approach systematically discovers all reachable non-terminals by following production rules as if they were graph edges. As symbols are discovered, they're marked as accessible in the tracking set. After the traversal completes, the function performs surgical pruning - filtering both the non-terminal set and the production rules to retain only elements reachable from the start symbol. This optimization step eliminates "dead" grammar components that contribute nothing to the language generation.

### eliminate_nonproductive_symbols method

For a grammar to be useful, each non-terminal should ultimately generate terminal strings. The `eliminate_nonproductive_symbols` function identifies and removes symbols that fail this crucial test:

```python
def eliminate_nonproductive_symbols(self):
    productive = set()

    for left, rights in self.P.items():
        for rule in rights:
            if rule == 'ε' or all(sym in self.Vt for sym in rule.split()):
                productive.add(left)
                break

    changed = True
    while changed:
        changed = False
        for left, rights in self.P.items():
            if left in productive:
                continue

            for rule in rights:
                if all(sym in self.Vt or sym in productive for sym in rule.split()):
                    productive.add(left)
                    changed = True
                    break

    if self.S not in productive:
        raise ValueError("Grammar does not generate any strings (start symbol is not productive)")

    self.Vn = [nt for nt in self.Vn if nt in productive]

    new_P = {}
    for left in self.Vn:
        new_rules = []
        for rule in self.P.get(left, []):
            symbols = rule.split()
            if rule == 'ε' or all(sym in self.Vt or sym in productive for sym in symbols):
                new_rules.append(rule)
        if new_rules:
            new_P[left] = new_rules

    self.P = new_P
```

This algorithm takes a bottom-up approach to identifying productive symbols. First, it identifies the obvious cases - non-terminals that directly produce terminal strings. Then, through iterative refinement, it discovers non-terminals that can produce terminal strings through multi-step derivations. The implementation uses a fixed-point iteration pattern, continuing until no new productive symbols are discovered.

A critical validation occurs when the algorithm checks whether the start symbol is productive. If not, an exception is raised since such a grammar cannot generate any strings - a fundamental flaw. The final cleansing phase removes all non-productive elements from both the non-terminal set and the production rules, including the subtle case of productions containing non-productive symbols within their right-hand sides.

### _ensure_terminal_rules method

Approaching the final CNF requirements, the algorithm must ensure terminals only appear in dedicated production rules. The ingenious `_ensure_terminal_rules` function accomplishes this transformation:

```python
def _ensure_terminal_rules(self):
    for term in self.Vt:
        new_nonterm = self._get_new_nonterminal('T')
        self.terminal_map[term] = new_nonterm
        self.Vn.append(new_nonterm)
        self.P[new_nonterm] = [term]

    for left in list(self.P.keys()):
        new_rules = []
        for rule in self.P[left]:
            symbols = rule.split()
            if len(symbols) == 1 and symbols[0] in self.Vt:
                new_rules.append(rule)
            else:
                new_rule = []
                for sym in symbols:
                    if sym in self.Vt:
                        new_rule.append(self.terminal_map[sym])
                    else:
                        new_rule.append(sym)
                new_rules.append(' '.join(new_rule))
        self.P[left] = new_rules
```

The implementation follows a two-phase strategy. In the first phase, it creates a dedicated non-terminal for each terminal symbol in the grammar, adding simple production rules that connect these non-terminals to their corresponding terminals. The function tracks these substitutions in the `terminal_map` dictionary for consistent replacement.

The second phase performs surgical modifications on mixed rules. While preserving simple rules of the form A → a (already CNF-compliant), it systematically replaces all terminal occurrences in longer rules with their corresponding non-terminal substitutes. This clever transformation ensures that terminal symbols only appear in isolation on the right side of productions, satisfying a key CNF requirement without changing the language generated by the grammar.

### _split_long_rules method

The final structural requirement of CNF demands that right-hand sides contain at most two non-terminals. The `_split_long_rules` function elegantly handles this constraint through recursive decomposition:

```python
def _split_long_rules(self):
    for left in list(self.P.keys()):
        new_rules = []
        for rule in self.P[left]:
            symbols = rule.split()
            if len(symbols) <= 2:
                new_rules.append(rule)  
            elif len(symbols) > 2:
                current_symbols = symbols
                while len(current_symbols) > 2:
                    first_two = ' '.join(current_symbols[:2])
                    if first_two not in self.pair_map:
                        new_nonterm = self._get_new_nonterminal('N')
                        self.pair_map[first_two] = new_nonterm
                        self.Vn.append(new_nonterm)
                        self.P[new_nonterm] = [first_two]

                    current_symbols = [self.pair_map[first_two]] + current_symbols[2:]

                new_rules.append(' '.join(current_symbols))

        self.P[left] = new_rules
```

The implementation tackles long productions through a left-to-right chunking strategy. For each rule with more than two symbols, it creates intermediate non-terminals that represent adjacent symbol pairs. The function intelligently caches these substitutions in the `pair_map` dictionary, reusing them across the grammar to minimize the number of new non-terminals introduced.

Consider the transformation of a rule like A → BCDE: the algorithm first creates a non-terminal N0 for the pair "B C", yielding A → N0 D E. In the next iteration, it might create N1 for "N0 D", resulting in A → N1 E. Since this production now has only two symbols, the process stops. The final grammar contains the additional rules N0 → B C and N1 → N0 D, effectively breaking the original four-symbol production into a set of binary ones without changing the generated language.

### normalize method

The `normalize` method serves as the conductor, orchestrating all transformation steps in the correct sequence:

```python
def normalize(self):
    print("Initial grammar:")
    print(self)

    self.eliminate_epsilons()
    print("\nAfter ε-elimination:")
    print(self)

    self.eliminate_unit_rules()
    print("\nAfter unit rule elimination:")
    print(self)

    self.eliminate_inaccessible_symbols()
    print("\nAfter removing inaccessible symbols:")
    print(self)

    self.eliminate_nonproductive_symbols()
    print("\nAfter removing non-productive symbols:")
    print(self)

    self.convert_to_cnf()
    print("\nFinal CNF:")
    print(self)

    return self
```

This method applies each transformation step sequentially, with useful debug output after each phase. The order is carefully designed: first addressing ε-productions, then unit rules, followed by accessibility and productivity checks, and finally applying the structural transformations to achieve CNF.

## Results

To validate the implementation, I tested the `ChomskyNormalizer` with two different grammar variants:


```
Initial grammar:
A -> a | a S | b C a C b
B -> A C | b S | a A a
C -> ε | A B
E -> B A
S -> b A C | B
After ε-elimination:
A -> a | b C a C b | a S | b C a b | b a b | b a C b
B -> b S | A | A C | a A a
C -> A B
E -> B A
S -> b A | B | b A C
After unit rule elimination:
A -> a | b C a C b | a S | b C a b | b a b | b a C b
B -> a | b C a C b | a S | b C a b | b a b | b a C b | b S | A C | a A a
C -> A B
E -> B A
S -> b A | b A C | a | b C a C b | a S | b C a b | b a b | b a C b | b S | A C | a A a
After removing inaccessible symbols:
A -> a | b C a C b | a S | b C a b | b a b | b a C b
B -> a | b C a C b | a S | b C a b | b a b | b a C b | b S | A C | a A a
C -> A B
S -> b A | b A C | a | b C a C b | a S | b C a b | b a b | b a C b | b S | A C | a A a
After removing non-productive symbols:
A -> a | b C a C b | a S | b C a b | b a b | b a C b
B -> a | b C a C b | a S | b C a b | b a b | b a C b | b S | A C | a A a
C -> A B
S -> b A | b A C | a | b C a C b | a S | b C a b | b a b | b a C b | b S | A C | a A a
Final CNF:
A -> a | N6 T2 | T1 S | N5 T2 | N7 T2 | N8 T2
B -> a | N6 T2 | T1 S | N5 T2 | N7 T2 | N8 T2 | T2 S | A C | N9 T1
C -> A B
N3 -> T2 A
N4 -> T2 C
N5 -> N4 T1
N6 -> N5 C
N7 -> T2 T1
N8 -> N7 C
N9 -> T1 A
S -> T2 A | N3 C | a | N6 T2 | T1 S | N5 T2 | N7 T2 | N8 T2 | T2 S | A C | N9 T1
S0 -> T2 A | N3 C | a | N6 T2 | T1 S | N5 T2 | N7 T2 | N8 T2 | T2 S | A C | N9 T1
T1 -> a
T2 -> b
```

### Variant 10 Test

```
Initial grammar:
A -> d | d S | a A a A b | ε
B -> a | a S | B A
D -> A b a
S -> d B | S A B
After ε-elimination:
A -> a a A b | a A a A b | d | a a b | a A a b | d S
B -> a | B A | B | a S
D -> b a | A b a
S -> S B | S A B | d B
After unit rule elimination:
A -> a a A b | a A a A b | d | a a b | a A a b | d S
B -> a | B A | a S
D -> b a | A b a
S -> S B | S A B | d B
After removing inaccessible symbols:
A -> a a A b | a A a A b | d | a a b | a A a b | d S
B -> a | B A | a S
S -> S B | S A B | d B
After removing non-productive symbols:
A -> a a A b | a A a A b | d | a a b | a A a b | d S
B -> a | B A | a S
S -> S B | S A B | d B
Final CNF:
A -> N6 T2 | N9 T2 | d | N5 T2 | N8 T2 | T3 S
B -> a | B A | T1 S
N4 -> S A
N5 -> T1 T1
N6 -> N5 A
N7 -> T1 A
N8 -> N7 T1
N9 -> N8 A
S -> S B | N4 B | T3 B
S0 -> S B | N4 B | T3 B
T1 -> a
T2 -> b
T3 -> d
```



## Conclusion

The `ChomskyNormalizer` implementation successfully transforms context-free grammars into Chomsky Normal Form through a systematic series of well-defined steps. The transformation process preserves the language generated by the original grammar while restructuring it to meet the strict constraints of CNF.

Key aspects of the implementation include:
1. **Robustness**: The normalizer handles various edge cases, including nullable start symbols, complex unit rule relationships, and long production rules.
2. **Generality**: The implementation works with any valid context-free grammar, not just specific variants.
3. **Efficiency**: The algorithms use sophisticated techniques like transitive closure, fixed-point iteration, and breadth-first search to efficiently transform the grammar.
4. **Clarity**: Each transformation step is clearly defined and implemented in a separate method, making the code easy to understand and maintain.

The implementation demonstrates the power and elegance of formal language transformations, highlighting how complex grammars can be systematically converted into a standardized form without changing their generative power. This normalization process not only simplifies theoretical analysis but also enables practical applications like efficient parsing.

The testing with different grammar variants confirms the correctness of the implementation and its ability to handle diverse grammar structures. The resulting CNF grammars maintain the languages of the original grammars while adhering to the stricter structural constraints required by CNF.

## References

[1] Hopcroft, J. E., Motwani, R., & Ullman, J. D. (2006). Introduction to Automata Theory, Languages, and Computation (3rd Edition). Pearson.

[2] Sipser, M. (2012). Introduction to the Theory of Computation (3rd Edition). Cengage Learning.

[3] Aho, A. V., Lam, M. S., Sethi, R., & Ullman, J. D. (2006). Compilers: Principles, Techniques, and Tools (2nd Edition). Addison Wesley.

[4] Parr, T. (2010). Language Implementation Patterns: Create Your Own Domain-Specific and General Programming Languages. Pragmatic Bookshelf.

[5] Formal Languages and Finite Automata, Guide for practical lessons. Retrieved from https://else.fcim.utm.md/pluginfile.php/110458/mod_resource/content/0/LFPC_Guide.pdf